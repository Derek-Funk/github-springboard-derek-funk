{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Now that we have our data in MySQL, let us answer some basic questions with Python. We will again use SQLAlchemy to do this.\n",
    "\n",
    "Running this whole notebook will prompt for your MySQL password and will only take a few seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model\n",
    "As a refresher, here is the database ERD that may help aid in coming up with some basic questions:\n",
    "![msd-erd](msd-erd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# DB connection set up\n",
    "server = 'localhost'\n",
    "database = 'songDB'\n",
    "port = 3306\n",
    "username = 'root'\n",
    "password = input()\n",
    "server_conn_string = f'mysql+mysqldb://{username}:{password}@{server}:{port}'\n",
    "db_name = 'msd' # million song dataset\n",
    "db_conn_string = server_conn_string + '/' + db_name\n",
    "engine = db.create_engine(db_conn_string)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How big is our database in terms of storage? How does this compare to the size of the raw data subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   db   gb\n",
      "0  information_schema  0.0\n",
      "1                 msd  2.3\n",
      "2               mysql  0.0\n",
      "3  performance_schema  0.0\n",
      "4                 sys  0.0\n"
     ]
    }
   ],
   "source": [
    "statement = 'SELECT table_schema \"msd\", ROUND(SUM(data_length + index_length) / 1024 / 1024 / 1024, 1) \"DB Size in GB\" FROM information_schema.tables GROUP BY table_schema; '\n",
    "ResultProxy = connection.execute(statement)\n",
    "size_of_all_dbs = pd.DataFrame(ResultProxy.fetchall(), columns=('db', 'gb'))\n",
    "print(size_of_all_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "size_of_msd = float(size_of_all_dbs.gb[size_of_all_dbs.db.eq('msd')])\n",
    "print(size_of_msd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.74\n",
      "84%\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_directory = Path('MillionSongSubset')\n",
    "raw_data_in_bytes = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file())\n",
    "raw_data_in_gb = round(raw_data_in_bytes / 1000**3, 2)\n",
    "print(raw_data_in_gb)\n",
    "percent_used = round(size_of_msd / raw_data_in_gb * 100)\n",
    "print(str(percent_used) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our raw data subset was 2.74 GB. During the database creation step, we extracted most of the information into MySQL, generating a database size of 2.3 GB. This represents 84% of the raw data subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How big are our tables in terms of rows, columns, and size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msd_artist', 'msd_artist_mbtag', 'msd_artist_similarity', 'msd_artist_term', 'msd_bar', 'msd_beat', 'msd_r_mbtag', 'msd_r_term', 'msd_section', 'msd_segment', 'msd_tatum', 'msd_track']\n"
     ]
    }
   ],
   "source": [
    "meta = db.MetaData()\n",
    "meta.reflect(bind=engine)\n",
    "list_of_tables = list(meta.tables.keys())\n",
    "print(list_of_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_sizes = pd.DataFrame(columns=('table', 'row count', 'col count', 'size in MB'))\n",
    "\n",
    "for table in list_of_tables:\n",
    "    statement = f'SELECT COUNT(*) FROM {table};'\n",
    "    ResultProxy = connection.execute(statement)\n",
    "    row_count = ResultProxy.fetchall()[0][0]\n",
    "\n",
    "    statement = f'SELECT COUNT(*) FROM information_schema.columns WHERE TABLE_SCHEMA = \"msd\" AND TABLE_NAME = \"{table}\";'\n",
    "    ResultProxy = connection.execute(statement)\n",
    "    col_count = ResultProxy.fetchall()[0][0]\n",
    "\n",
    "    statement = f'SELECT ROUND((data_length + index_length) / 1024 / 1024, 3) FROM information_schema.tables WHERE table_schema = \"msd\" AND table_name = \"{table}\";'\n",
    "    ResultProxy = connection.execute(statement)\n",
    "    size_mb = float(ResultProxy.fetchall()[0][0])\n",
    "\n",
    "    new_row = {'table': table, 'row count': row_count, 'col count': col_count, 'size in MB': size_mb}\n",
    "    table_sizes = table_sizes.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    table row count col count  size in MB\n",
      "9             msd_segment   8577406        32    1414.000\n",
      "10              msd_tatum  10479481         5     538.000\n",
      "5                msd_beat   4809945         5     267.766\n",
      "4                 msd_bar   1649792         5      90.609\n",
      "8             msd_section     99897         5       6.516\n",
      "3         msd_artist_term     97493         3       5.516\n",
      "2   msd_artist_similarity     42969         3       3.516\n",
      "11              msd_track     10000        22       3.516\n",
      "0              msd_artist      3888         5       0.391\n",
      "1        msd_artist_mbtag      3804         3       0.234\n",
      "7              msd_r_term      3502         2       0.156\n",
      "6             msd_r_mbtag       721         2       0.063\n"
     ]
    }
   ],
   "source": [
    "print(table_sizes.sort_values(by='size in MB', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest tables are msd_segment, msd_tatum, msd_beat, and msd_bar. This makes sense because for each song, there can be hundreds of bars, beats, and notes (segment/tatum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How many artists span the 10,000 songs? If some artists have more than 1 song in this data subset, what is the distribution like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888\n"
     ]
    }
   ],
   "source": [
    "statement = 'SELECT COUNT(*) FROM msd_artist;'\n",
    "ResultProxy = connection.execute(statement)\n",
    "artist_count = ResultProxy.fetchall()[0][0]\n",
    "print(artist_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3,888 unique artists, meaning some artists have multiple songs in this data set. Below are the top 10 artists by song count in this data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mario Rosenstock', 13),\n",
       " ('Snow Patrol', 12),\n",
       " ('The Jackson Southernaires', 12),\n",
       " ('Sugar Minott', 12),\n",
       " ('RUN-DMC', 12),\n",
       " ('Line Renaud', 12),\n",
       " ('Aerosmith', 12),\n",
       " ('Phil Collins', 12),\n",
       " ('Nick Cave & The Bad Seeds', 11),\n",
       " ('Stevie Ray Vaughan And Double Trouble', 11)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = 'WITH top_10_artist AS ('\\\n",
    "'SELECT artist_id, COUNT(*) AS song_count FROM msd_track GROUP BY artist_id ORDER BY song_count DESC LIMIT 10)'\\\n",
    "'SELECT a.artist_name, t.song_count FROM top_10_artist AS t LEFT JOIN msd_artist AS a ON t.artist_id = a.artist_id;'\n",
    "ResultProxy = connection.execute(statement)\n",
    "ResultProxy.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the distribution of the songs' years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  song_count\n",
      "0      NaN        5320\n",
      "1   2006.0         320\n",
      "2   2005.0         304\n",
      "3   2007.0         285\n",
      "4   2004.0         270\n",
      "..     ...         ...\n",
      "64  1936.0           1\n",
      "65  1934.0           1\n",
      "66  1950.0           1\n",
      "67  1929.0           1\n",
      "68  1957.0           1\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "statement = 'SELECT year, COUNT(*) AS year_count FROM msd_track GROUP BY year ORDER BY year_count DESC;'\n",
    "ResultProxy = connection.execute(statement)\n",
    "song_dist = pd.DataFrame(ResultProxy.fetchall(), columns=('year', 'song_count'))\n",
    "print(song_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5320\n"
     ]
    }
   ],
   "source": [
    "missing_year = song_dist.song_count[song_dist.year.isna()][0]\n",
    "print(missing_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1926.0\n",
      "2010.0\n"
     ]
    }
   ],
   "source": [
    "song_dist_clean = song_dist[song_dist.year.notna()]\n",
    "print(min(song_dist_clean.year))\n",
    "print(max(song_dist_clean.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  song_count\n",
      "1   2006.0         320\n",
      "2   2005.0         304\n",
      "3   2007.0         285\n",
      "4   2004.0         270\n",
      "5   2003.0         254\n",
      "6   2008.0         253\n",
      "7   2009.0         250\n",
      "8   2001.0         217\n",
      "9   2002.0         198\n",
      "10  2000.0         192\n"
     ]
    }
   ],
   "source": [
    "print(song_dist_clean.iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About half of the songs in our data subset have missing years. For songs that we do have years, the songs range from 1926 to 2010, with the most coming from the 00s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "64    False\n",
       "65    False\n",
       "66    False\n",
       "67    False\n",
       "68    False\n",
       "Name: year, Length: 69, dtype: bool"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_dist.year.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What are the \"hottest\" songs in this subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    artist                                               song  \\\n",
      "0                    B.o.B  Nothin' On You [feat. Bruno Mars] (Album Version)   \n",
      "1             Led Zeppelin                     Immigrant Song (Album Version)   \n",
      "2           Donny Hathaway                        This Christmas (LP Version)   \n",
      "3               Nickelback         If Today Was Your Last Day (Album Version)   \n",
      "4                 Maroon 5                                  Harder To Breathe   \n",
      "5        The White Stripes                                        Blue Orchid   \n",
      "6              Snow Patrol                                       Just Say Yes   \n",
      "7  Pete Rock & C.L. Smooth           They Reminisce Over You (Single Version)   \n",
      "8                     Muse             Exogenesis: Symphony Part 1 [Overture]   \n",
      "9           The Mars Volta                                     Inertiatic Esp   \n",
      "\n",
      "    hotness  \n",
      "0  1.000000  \n",
      "1  1.000000  \n",
      "2  0.997758  \n",
      "3  0.984347  \n",
      "4  0.979837  \n",
      "5  0.972387  \n",
      "6  0.945995  \n",
      "7  0.932274  \n",
      "8  0.931346  \n",
      "9  0.928617  \n"
     ]
    }
   ],
   "source": [
    "statement = 'SELECT a.artist_name, t.title AS song, t.song_hotness '\\\n",
    "'FROM msd_track AS t INNER JOIN msd_artist AS a ON t.artist_id = a.artist_id WHERE t.song_hotness IS NOT NULL ORDER BY t.song_hotness DESC LIMIT 10;'\n",
    "ResultProxy = connection.execute(statement)\n",
    "song_hotness = pd.DataFrame(ResultProxy.fetchall(), columns=('artist', 'song', 'hotness'))\n",
    "print(song_hotness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Connection.close of <sqlalchemy.engine.base.Connection object at 0x7f9b8688d640>>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Considerations\n",
    "- some columns seem to always be null, should we remove\n",
    "- we skipped importing term/tag likelihoods, this could help with effectively designating a single genre per track\n",
    "- still some normalization can be made\n",
    "- some fields still have codes that don't have reference tables and need to be looked into (e.g. key, mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
